{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "\n",
    "from modules.comp.comp_d_net_pl import *\n",
    "from modules.mono.depth_net_pl import *\n",
    "from modules.mv.mv_depth_net_pl import *\n",
    "from utils.data_utils import *\n",
    "from utils.localization_utils import *\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as Lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = \"d\"#\"comp\"#\n",
    "\n",
    "# dataset = \"gibson_f\"\n",
    "# #dataset_path = \"/cluster/scratch/wueestm/gibson/Gibson_Floorplan_Localization_Dataset\"\n",
    "# dataset_path= \"/cluster/project/cvg/data/gibson/Gibson_Floorplan_Localization_Dataset\"\n",
    "\n",
    "dataset = \"hge_customized_cropped\"\n",
    "dataset_path = \"/cluster/project/cvg/data/lamar/HGE_customized_cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= USING DEVICE :  cpu  =======\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"======= USING DEVICE : \", device, \" =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "L = 0  # number of the source frames\n",
    "D = 128  # number of depth planes\n",
    "d_min = 0.1  # minimum depth\n",
    "d_max = 15.0  # maximum depth\n",
    "d_hyp = -0.2  # depth transform (uniform sampling in d**d_hyp)\n",
    "#F_W = 3 / 8  # camera intrinsic, focal length / image width\n",
    "#trans_thresh = 0.005  # translation threshold (variance) if using comp_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_rp = (\n",
    "    True  # whether use roll and pitch angle augmentation, only used in training\n",
    ")\n",
    "roll = 0.00001  # maximum roll augmentation in radian\n",
    "pitch = 0.00001  # maximum pitch augmentation in radian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "dataset_dir = os.path.join(dataset_path, dataset)\n",
    "depth_dir = dataset_dir\n",
    "#log_dir = ckpt_path\n",
    "desdf_path = os.path.join(dataset_path, \"desdf\")\n",
    "\n",
    "if (net_type == \"d\") & (dataset == \"hge_customized_cropped\"):\n",
    "    depth_suffix = \"depth90\"\n",
    "elif net_type == \"d\":\n",
    "    depth_suffix = \"depth40\"\n",
    "else:\n",
    "    depth_suffix = \"depth160\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset\n",
    "split_file = os.path.join(dataset_dir, \"split.yaml\")\n",
    "with open(split_file, \"r\") as f:\n",
    "    split = AttrDict(yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.scene_names:  ('ios_2022-01-12_15.15.53_000', 'ios_2022-01-18_17.05.03_000', 'ios_2022-01-18_17.10.39_000', 'ios_2022-01-20_16.52.33_001', 'ios_2022-01-25_14.34.24_002', 'ios_2022-01-25_14.57.49_000', 'ios_2022-01-25_15.13.54_000', 'ios_2022-06-13_10.45.07_000', 'ios_2022-06-13_15.59.36_000', 'ios_2022-06-14_17.12.28_000', 'ios_2022-06-30_15.55.53_000', 'ios_2022-07-01_15.18.09_000')\n",
      "scene:  ios_2022-01-12_15.15.53_000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:  ios_2022-01-18_17.05.03_000\n",
      "scene:  ios_2022-01-18_17.10.39_000\n",
      "scene:  ios_2022-01-20_16.52.33_001\n",
      "scene:  ios_2022-01-25_14.34.24_002\n",
      "scene:  ios_2022-01-25_14.57.49_000\n",
      "scene:  ios_2022-01-25_15.13.54_000\n",
      "scene:  ios_2022-06-13_10.45.07_000\n",
      "scene:  ios_2022-06-13_15.59.36_000\n",
      "scene:  ios_2022-06-14_17.12.28_000\n",
      "scene:  ios_2022-06-30_15.55.53_000\n",
      "scene:  ios_2022-07-01_15.18.09_000\n",
      "self.scene_names:  ('ios_2022-07-01_15.45.08_000', 'ios_2022-07-01_15.58.10_000', 'ios_2022-01-18_17.10.39_000')\n",
      "scene:  ios_2022-07-01_15.45.08_000\n",
      "scene:  ios_2022-07-01_15.58.10_000\n",
      "scene:  ios_2022-01-18_17.10.39_000\n"
     ]
    }
   ],
   "source": [
    "# Define data\n",
    "train_dataset = GridSeqDataset_hge_customized_cropped_gravity_align(\n",
    "    dataset_dir,\n",
    "    split.train,\n",
    "    L=L,\n",
    "    depth_dir=depth_dir,\n",
    "    depth_suffix=depth_suffix,\n",
    "    add_rp=add_rp,\n",
    "    roll=roll,\n",
    "    pitch=pitch,\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = GridSeqDataset_hge_customized_cropped_gravity_align(\n",
    "    dataset_dir,\n",
    "    split.val,\n",
    "    L=L,\n",
    "    depth_dir=depth_dir,\n",
    "    depth_suffix=depth_suffix,\n",
    "    add_rp=add_rp,\n",
    "    roll=roll,\n",
    "    pitch=pitch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define model \n",
    "model = depth_net_pl(d_min=d_min, d_max=d_max, d_hyp=d_hyp, D=D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger  # Import TensorBoardLogger\n",
    "\n",
    "# Setup TensorBoard logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cluster/home/wueestm/anaconda3/envs/f3loc/lib/pytho ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | encoder | depth_net | 25.9 M\n",
      "--------------------------------------\n",
      "25.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.9 M    Total params\n",
      "103.726   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bd2e1ca41849e7bf35e4fef96025b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/cluster/home/wueestm/anaconda3/envs/f3loc/lib/python3.8/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#trainer = Lightning.Trainer(max_steps=10, max_epochs=1, enable_checkpointing=True)\n",
    "trainer = Lightning.Trainer(max_epochs=1, enable_checkpointing=True, logger=logger)\n",
    "#trainer = Lightning.Trainer(max_epochs=100, enable_checkpointing=True, logger=logger)\n",
    "#trainer = Lightning.Trainer(max_steps=8, max_epochs=1, enable_checkpointing=True)\n",
    "#trainer = Lightning.Trainer(max_epochs=8, enable_checkpointing=True)\n",
    "#trainer = Lightning.Trainer(fast_dev_run=10, enable_checkpointing=True)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
